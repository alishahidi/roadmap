"use strict";(self.webpackChunkroadmap=self.webpackChunkroadmap||[]).push([[4383],{2121:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>u,frontMatter:()=>o,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"06-observability-and-performance","title":"Observability & Performance","description":"Building a system is one thing; ensuring it runs well and can handle growth is another. This final section covers two deeply intertwined topics: observability (the ability to understand your system\'s internal state from the outside) and performance (the strategies for making your system faster and more scalable). You can\'t improve what you can\'t measure.","source":"@site/docs/06-observability-and-performance.mdx","sourceDirName":".","slug":"/observability-and-performance","permalink":"/roadmap/docs/observability-and-performance","draft":false,"unlisted":false,"editUrl":"https://github.com/alishahidi/roadmap/tree/main/docs/06-observability-and-performance.mdx","tags":[],"version":"current","sidebarPosition":6,"frontMatter":{"id":"06-observability-and-performance","slug":"/observability-and-performance","sidebar_position":6,"title":"Observability & Performance"},"sidebar":"roadmapSidebar","previous":{"title":"Deployment & Operations","permalink":"/roadmap/docs/deployment-and-operations"}}');var s=r(4848),i=r(8453);const o={id:"06-observability-and-performance",slug:"/observability-and-performance",sidebar_position:6,title:"Observability & Performance"},a=void 0,l={},c=[{value:"Observability: The Three Pillars",id:"observability-the-three-pillars",level:2},{value:"1. Logging Implementation Examples",id:"1-logging-implementation-examples",level:3},{value:"2. Metrics Collection with Prometheus",id:"2-metrics-collection-with-prometheus",level:3},{value:"3. Distributed Tracing with OpenTelemetry",id:"3-distributed-tracing-with-opentelemetry",level:3},{value:"Four Golden Signals Dashboard Configuration",id:"four-golden-signals-dashboard-configuration",level:3},{value:"Service Level Objectives (SLOs) &amp; Error Budgets",id:"service-level-objectives-slos--error-budgets",level:2},{value:"The SLI/SLO/SLA Hierarchy",id:"the-slislosla-hierarchy",level:3},{value:"Error Budgets",id:"error-budgets",level:3},{value:"Common SLIs for Backend Services",id:"common-slis-for-backend-services",level:3},{value:"Fundamental Scaling Strategies",id:"fundamental-scaling-strategies",level:2}];function d(e){const n={a:"a",admonition:"admonition",code:"code",h2:"h2",h3:"h3",hr:"hr",li:"li",mermaid:"mermaid",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components},{Details:r}=n;return r||function(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Details",!0),(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.p,{children:"Building a system is one thing; ensuring it runs well and can handle growth is another. This final section covers two deeply intertwined topics: observability (the ability to understand your system's internal state from the outside) and performance (the strategies for making your system faster and more scalable). You can't improve what you can't measure."}),"\n",(0,s.jsx)(n.h2,{id:"observability-the-three-pillars",children:"Observability: The Three Pillars"}),"\n",(0,s.jsx)(n.p,{children:"Observability is crucial for debugging complex, distributed systems. It's not just about having dashboards; it's about being able to ask arbitrary questions about your system to understand \"unknown unknowns.\" It is built on three pillars:"}),"\n",(0,s.jsx)(n.mermaid,{value:'graph TD\n    A[Request] --\x3e B{Service A};\n    B --\x3e C{Service B};\n    B --\x3e D{Service C};\n\n    subgraph Observability Platform\n        E[Logs]\n        F[Metrics]\n        G[Traces]\n    end\n\n    B -- Emits --\x3e E;\n    C -- Emits --\x3e E;\n    D -- Emits --\x3e E;\n\n    B -- Emits --\x3e F;\n    C -- Emits --\x3e F;\n    D -- Emits --\x3e F;\n\n    A -- "Trace ID" --\x3e B;\n    B -- "Trace ID" --\x3e C;\n    B -- "Trace ID" --\x3e D;\n    B -- "Span" --\x3e G;\n    C -- "Span" --\x3e G;\n    D -- "Span" --\x3e G;'}),"\n",(0,s.jsx)(n.h3,{id:"1-logging-implementation-examples",children:"1. Logging Implementation Examples"}),"\n",(0,s.jsxs)(r,{children:[(0,s.jsx)("summary",{children:"Structured Logging with Winston (Node.js)"}),(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-javascript",children:"const winston = require('winston');\nconst { ElasticsearchTransport } = require('winston-elasticsearch');\n\nconst logger = winston.createLogger({\n  level: 'info',\n  format: winston.format.combine(\n    winston.format.timestamp(),\n    winston.format.errors({ stack: true }),\n    winston.format.json()\n  ),\n  defaultMeta: { \n    service: 'user-service',\n    version: process.env.APP_VERSION || '1.0.0'\n  },\n  transports: [\n    // Console for development\n    new winston.transports.Console({\n      format: winston.format.combine(\n        winston.format.colorize(),\n        winston.format.simple()\n      )\n    }),\n    \n    // File for production\n    new winston.transports.File({ \n      filename: 'logs/error.log', \n      level: 'error' \n    }),\n    new winston.transports.File({ \n      filename: 'logs/combined.log' \n    }),\n    \n    // Elasticsearch for centralized logging\n    new ElasticsearchTransport({\n      level: 'info',\n      clientOpts: { node: process.env.ELASTICSEARCH_URL },\n      index: 'application-logs'\n    })\n  ]\n});\n\n// Usage in application\nclass UserService {\n  async createUser(userData) {\n    const userId = crypto.randomUUID();\n    \n    logger.info('Creating user', {\n      operation: 'create_user',\n      userId,\n      email: userData.email,\n      metadata: {\n        ip: req.ip,\n        userAgent: req.get('User-Agent')\n      }\n    });\n    \n    try {\n      const user = await this.userRepository.create({\n        id: userId,\n        ...userData\n      });\n      \n      logger.info('User created successfully', {\n        operation: 'create_user',\n        userId,\n        duration: Date.now() - startTime\n      });\n      \n      return user;\n    } catch (error) {\n      logger.error('Failed to create user', {\n        operation: 'create_user',\n        userId,\n        error: error.message,\n        stack: error.stack,\n        userData: { email: userData.email } // Don't log sensitive data\n      });\n      throw error;\n    }\n  }\n}\n"})})]}),"\n",(0,s.jsx)(n.h3,{id:"2-metrics-collection-with-prometheus",children:"2. Metrics Collection with Prometheus"}),"\n",(0,s.jsxs)(r,{children:[(0,s.jsx)("summary",{children:"Express.js Metrics Middleware"}),(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-javascript",children:"const prometheus = require('prom-client');\nconst express = require('express');\n\n// Create metrics\nconst httpRequestsTotal = new prometheus.Counter({\n  name: 'http_requests_total',\n  help: 'Total number of HTTP requests',\n  labelNames: ['method', 'route', 'status_code']\n});\n\nconst httpRequestDuration = new prometheus.Histogram({\n  name: 'http_request_duration_seconds',\n  help: 'Duration of HTTP requests in seconds',\n  labelNames: ['method', 'route', 'status_code'],\n  buckets: [0.1, 0.5, 1, 2, 5]\n});\n\nconst activeConnections = new prometheus.Gauge({\n  name: 'active_connections',\n  help: 'Number of active connections'\n});\n\nconst databaseConnectionPool = new prometheus.Gauge({\n  name: 'database_connection_pool_active',\n  help: 'Active database connections in pool'\n});\n\n// Middleware to collect metrics\nconst metricsMiddleware = (req, res, next) => {\n  const startTime = Date.now();\n  \n  activeConnections.inc();\n  \n  res.on('finish', () => {\n    const duration = (Date.now() - startTime) / 1000;\n    const route = req.route?.path || req.path;\n    \n    httpRequestsTotal\n      .labels(req.method, route, res.statusCode.toString())\n      .inc();\n    \n    httpRequestDuration\n      .labels(req.method, route, res.statusCode.toString())\n      .observe(duration);\n    \n    activeConnections.dec();\n  });\n  \n  next();\n};\n\n// Custom business metrics\nconst orderMetrics = {\n  ordersCreated: new prometheus.Counter({\n    name: 'orders_created_total',\n    help: 'Total number of orders created',\n    labelNames: ['payment_method', 'customer_segment']\n  }),\n  \n  orderValue: new prometheus.Histogram({\n    name: 'order_value_dollars',\n    help: 'Order value in dollars',\n    buckets: [10, 50, 100, 250, 500, 1000]\n  }),\n  \n  inventoryLevel: new prometheus.Gauge({\n    name: 'inventory_level',\n    help: 'Current inventory level',\n    labelNames: ['product_id', 'warehouse']\n  })\n};\n\n// Usage in business logic\nclass OrderService {\n  async createOrder(orderData) {\n    try {\n      const order = await this.orderRepository.create(orderData);\n      \n      // Track business metrics\n      orderMetrics.ordersCreated\n        .labels(order.paymentMethod, order.customerSegment)\n        .inc();\n        \n      orderMetrics.orderValue\n        .observe(order.totalAmount);\n      \n      return order;\n    } catch (error) {\n      // Error metrics are tracked automatically by middleware\n      throw error;\n    }\n  }\n}\n\n// Metrics endpoint\napp.use('/metrics', async (req, res) => {\n  try {\n    // Update gauge metrics before serving\n    const dbPool = await db.getPoolStatus();\n    databaseConnectionPool.set(dbPool.activeConnections);\n    \n    res.set('Content-Type', prometheus.register.contentType);\n    res.end(await prometheus.register.metrics());\n  } catch (error) {\n    res.status(500).end(error.message);\n  }\n});\n"})})]}),"\n",(0,s.jsx)(n.h3,{id:"3-distributed-tracing-with-opentelemetry",children:"3. Distributed Tracing with OpenTelemetry"}),"\n",(0,s.jsxs)(r,{children:[(0,s.jsx)("summary",{children:"OpenTelemetry Setup"}),(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-javascript",children:"const { NodeSDK } = require('@opentelemetry/sdk-node');\nconst { Resource } = require('@opentelemetry/resources');\nconst { SemanticResourceAttributes } = require('@opentelemetry/semantic-conventions');\nconst { JaegerExporter } = require('@opentelemetry/exporter-jaeger');\nconst { getNodeAutoInstrumentations } = require('@opentelemetry/auto-instrumentations-node');\n\n// Initialize OpenTelemetry\nconst sdk = new NodeSDK({\n  resource: new Resource({\n    [SemanticResourceAttributes.SERVICE_NAME]: 'user-service',\n    [SemanticResourceAttributes.SERVICE_VERSION]: '1.0.0',\n    [SemanticResourceAttributes.DEPLOYMENT_ENVIRONMENT]: process.env.NODE_ENV\n  }),\n  traceExporter: new JaegerExporter({\n    endpoint: 'http://jaeger:14268/api/traces'\n  }),\n  instrumentations: [\n    getNodeAutoInstrumentations({\n      '@opentelemetry/instrumentation-fs': {\n        enabled: false // Disable filesystem instrumentation\n      }\n    })\n  ]\n});\n\nsdk.start();\n\n// Manual instrumentation\nconst { trace, SpanStatusCode } = require('@opentelemetry/api');\n\nclass UserService {\n  async getUserWithOrders(userId) {\n    const tracer = trace.getTracer('user-service');\n    \n    return tracer.startActiveSpan('get_user_with_orders', async (span) => {\n      try {\n        span.setAttributes({\n          'user.id': userId,\n          'operation': 'get_user_with_orders'\n        });\n        \n        // Get user data\n        const user = await tracer.startActiveSpan('database.get_user', async (userSpan) => {\n          userSpan.setAttributes({\n            'db.operation': 'SELECT',\n            'db.table': 'users'\n          });\n          \n          const userData = await this.userRepository.findById(userId);\n          userSpan.setStatus({ code: SpanStatusCode.OK });\n          return userData;\n        });\n        \n        if (!user) {\n          span.recordException(new Error('User not found'));\n          span.setStatus({ \n            code: SpanStatusCode.ERROR, \n            message: 'User not found' \n          });\n          throw new Error('User not found');\n        }\n        \n        // Get user orders\n        const orders = await tracer.startActiveSpan('get_user_orders', async (ordersSpan) => {\n          ordersSpan.setAttributes({\n            'user.id': userId,\n            'operation': 'get_orders'\n          });\n          \n          const orderData = await this.orderService.getOrdersByUserId(userId);\n          ordersSpan.setAttributes({\n            'orders.count': orderData.length\n          });\n          \n          return orderData;\n        });\n        \n        span.setAttributes({\n          'user.email': user.email,\n          'orders.count': orders.length,\n          'result.success': true\n        });\n        \n        span.setStatus({ code: SpanStatusCode.OK });\n        return { user, orders };\n        \n      } catch (error) {\n        span.recordException(error);\n        span.setStatus({ \n          code: SpanStatusCode.ERROR, \n          message: error.message \n        });\n        throw error;\n      } finally {\n        span.end();\n      }\n    });\n  }\n}\n"})})]}),"\n",(0,s.jsx)(n.h3,{id:"four-golden-signals-dashboard-configuration",children:"Four Golden Signals Dashboard Configuration"}),"\n",(0,s.jsxs)(r,{children:[(0,s.jsx)("summary",{children:"Grafana Dashboard JSON"}),(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-json",children:'{\n  "dashboard": {\n    "title": "Application Golden Signals",\n    "panels": [\n      {\n        "title": "Request Rate (Traffic)",\n        "type": "graph",\n        "targets": [\n          {\n            "expr": "rate(http_requests_total[5m])",\n            "legendFormat": "{{method}} {{route}}"\n          }\n        ]\n      },\n      {\n        "title": "Request Latency",\n        "type": "graph",\n        "targets": [\n          {\n            "expr": "histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))",\n            "legendFormat": "95th percentile"\n          },\n          {\n            "expr": "histogram_quantile(0.50, rate(http_request_duration_seconds_bucket[5m]))",\n            "legendFormat": "50th percentile"\n          }\n        ]\n      },\n      {\n        "title": "Error Rate",\n        "type": "graph",\n        "targets": [\n          {\n            "expr": "rate(http_requests_total{status_code=~\\"5..\\"}[5m]) / rate(http_requests_total[5m])",\n            "legendFormat": "Error Rate"\n          }\n        ]\n      },\n      {\n        "title": "Saturation (CPU & Memory)",\n        "type": "graph",\n        "targets": [\n          {\n            "expr": "rate(process_cpu_seconds_total[5m]) * 100",\n            "legendFormat": "CPU Usage %"\n          },\n          {\n            "expr": "process_resident_memory_bytes / 1024 / 1024",\n            "legendFormat": "Memory Usage MB"\n          }\n        ]\n      }\n    ]\n  }\n}\n'})})]}),"\n",(0,s.jsx)(n.admonition,{title:"Deep Dive: Resources",type:"tip",children:(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:(0,s.jsxs)(n.a,{href:"https://www.honeycomb.io/blog/three-pillars-of-observability-logs-metrics-traces",children:["\ud83d\udcc4 ",(0,s.jsx)(n.strong,{children:"The Three Pillars of Observability"})," by Honeycomb.io"]})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsxs)(n.a,{href:"https://www.youtube.com/watch?v=y-G-iA-i5-Y",children:["\u25b6\ufe0f ",(0,s.jsx)(n.strong,{children:"What is OpenTelemetry?"})," (Video)"]})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsxs)(n.a,{href:"https://prometheus.io/docs/introduction/overview/",children:["\ud83d\udcc4 ",(0,s.jsx)(n.strong,{children:"Prometheus Official Documentation"})]})}),"\n"]})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"service-level-objectives-slos--error-budgets",children:"Service Level Objectives (SLOs) & Error Budgets"}),"\n",(0,s.jsx)(n.p,{children:"Senior engineers must define and measure service reliability using quantifiable metrics."}),"\n",(0,s.jsx)(n.h3,{id:"the-slislosla-hierarchy",children:"The SLI/SLO/SLA Hierarchy"}),"\n",(0,s.jsx)(n.mermaid,{value:'graph TD\n    A[SLA - Service Level Agreement] --\x3e B[SLO - Service Level Objective];\n    B --\x3e C[SLI - Service Level Indicator];\n    \n    A --\x3e A1["External commitment to users<br/>Legal/business consequence"];\n    B --\x3e B1["Internal reliability target<br/>What you aim for"];\n    C --\x3e C1["Actual measurement<br/>What you measure"];'}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"SLI (Service Level Indicator):"}),' A quantifiable measure of service level (e.g., "99.9% of requests return in under 100ms").']}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"SLO (Service Level Objective):"}),' The target reliability for a service, based on SLIs (e.g., "99.95% uptime").']}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"SLA (Service Level Agreement):"})," The legal/business agreement with consequences if not met."]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"error-budgets",children:"Error Budgets"}),"\n",(0,s.jsxs)(n.p,{children:["An ",(0,s.jsx)(n.strong,{children:"error budget"})," is the maximum amount of downtime/errors acceptable within a period (e.g., 0.1% error rate = 43.2 minutes downtime per month)."]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Benefits:"})," Balances reliability with development velocity. Teams can spend their error budget on new features."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"When Budget is Exceeded:"})," Focus shifts to reliability over new features."]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"common-slis-for-backend-services",children:"Common SLIs for Backend Services"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Availability:"})," Percentage of successful requests over total requests."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Latency:"})," Response time distribution (e.g., 95th percentile < 200ms)."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Throughput:"})," Requests per second the service can handle."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Error Rate:"})," Percentage of requests that result in errors."]}),"\n"]}),"\n",(0,s.jsx)(n.admonition,{title:"Deep Dive: Resources",type:"tip",children:(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:(0,s.jsxs)(n.a,{href:"https://sre.google/sre-book/table-of-contents/",children:["\ud83d\udcc4 ",(0,s.jsx)(n.strong,{children:"Site Reliability Engineering Book"})," (Google)"]})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsxs)(n.a,{href:"https://www.youtube.com/watch?v=tEylFyxbDLE",children:["\u25b6\ufe0f ",(0,s.jsx)(n.strong,{children:"SLIs, SLOs, SLAs, oh my!"})," (Video by Google)"]})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsxs)(n.a,{href:"https://www.datadoghq.com/blog/slo-monitoring-tracking/",children:["\ud83d\udcc4 ",(0,s.jsx)(n.strong,{children:"Implementing SLOs"})," (Datadog)"]})}),"\n"]})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"fundamental-scaling-strategies",children:"Fundamental Scaling Strategies"}),"\n",(0,s.jsx)(n.p,{children:"Scaling is the process of increasing a system's capacity to handle more load."}),"\n",(0,s.jsx)(n.mermaid,{value:'graph TD\n    subgraph "Vertical Scaling (Scale Up)"\n        A[User] --\x3e B((Server));\n        B -- "Add More RAM/CPU" --\x3e B;\n    end\n\n    subgraph "Horizontal Scaling (Scale Out)"\n        C[User] --\x3e D{Load Balancer};\n        D --\x3e E((Server 1));\n        D --\x3e F((Server 2));\n        D --\x3e G((Server ...));\n    end'}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Vertical Scaling (Scaling Up):"})," Increasing the resources (CPU, RAM) of a single server. It's simple to implement but has a hard physical limit and can be very expensive. It's also a single point of failure."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Horizontal Scaling (Scaling Out):"})," Adding more servers to a pool and distributing the load between them. This is the foundation of modern, scalable systems. It's more cost-effective and fault-tolerant but requires applications to be designed as ",(0,s.jsx)(n.strong,{children:"stateless"})," services."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Load Balancing:"})," A load balancer sits in front of your horizontally scaled services and distributes incoming traffic, preventing any single server from being overwhelmed."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Content Delivery Network (CDN):"})," A geographically distributed network of proxy servers that caches static content closer to users, dramatically reducing latency and offloading traffic from your origin servers."]}),"\n"]}),"\n",(0,s.jsx)(n.admonition,{title:"Deep Dive: Resources",type:"tip",children:(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:(0,s.jsxs)(n.a,{href:"https://www.youtube.com/watch?v=K0Ta65OqQkY",children:["\u25b6\ufe0f ",(0,s.jsx)(n.strong,{children:"System Design 101: Scaling and Load Balancers"})," (Video)"]})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsxs)(n.a,{href:"https://www.cloudflare.com/learning/cdn/what-is-a-cdn/",children:["\ud83d\udcc4 ",(0,s.jsx)(n.strong,{children:"What is a CDN?"})," (Cloudflare)"]})}),"\n"]})})]})}function u(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}}}]);